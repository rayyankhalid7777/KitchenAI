# Importing necessary libraries
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.metrics import accuracy_score, classification_report
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import load_breast_cancer

# Function to load the Adult Income dataset
def load_adult_dataset():
    url = "https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data"
    columns = [
        "age", "workclass", "fnlwgt", "education", "education-num", "marital-status",
        "occupation", "relationship", "race", "sex", "capital-gain", "capital-loss",
        "hours-per-week", "native-country", "income"
    ]
    data = pd.read_csv(url, names=columns, header=None, na_values=" ?")
    data.dropna(inplace=True)
    data['income'] = data['income'].apply(lambda x: 1 if x == " >50K" else 0)
    X = pd.get_dummies(data.iloc[:, :-1], drop_first=True)
    y = data['income'].values
    return X, y

# Function to load the Bank Marketing dataset
import zipfile
import requests
from io import BytesIO
import pandas as pd

def load_bank_dataset():
    url = "https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank.zip"
    response = requests.get(url)
    
    # Open the ZIP file and extract the specific file
    with zipfile.ZipFile(BytesIO(response.content)) as z:
        with z.open('bank.csv') as f:
            data = pd.read_csv(f, sep=";")
    
    data['y'] = data['y'].apply(lambda x: 1 if x == "yes" else 0)
    X = pd.get_dummies(data.iloc[:, :-1], drop_first=True)
    y = data['y'].values
    return X, y



# Function to evaluate classifiers
def evaluate_classifier(classifier, param_grid, X_train, y_train, X_test, y_test):
    grid_search = GridSearchCV(classifier, param_grid, cv=3, scoring='accuracy')
    grid_search.fit(X_train, y_train)
    best_model = grid_search.best_estimator_
    train_accuracy = accuracy_score(y_train, best_model.predict(X_train))
    test_accuracy = accuracy_score(y_test, best_model.predict(X_test))
    class_report = classification_report(y_test, best_model.predict(X_test))
    return train_accuracy, test_accuracy, grid_search.best_params_, class_report

# Load datasets
datasets = {
    "Breast Cancer": load_breast_cancer(return_X_y=True),
    "Adult Income": load_adult_dataset(),
    "Bank Marketing": load_bank_dataset()
}

# Classifiers and hyperparameter grids
classifiers = {
    "SVM": (SVC(), {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}),
    "Random Forest": (RandomForestClassifier(), {'n_estimators': [10, 50, 100], 'max_depth': [None, 10, 20]}),
    "k-NN": (KNeighborsClassifier(), {'n_neighbors': [3, 5, 7]})
}

# Train-test splits
splits = [(0.2, 0.8), (0.5, 0.5), (0.8, 0.2)]

detailed_results = []

# Main experiment loop
for dataset_name, (X, y) in datasets.items():
    X = StandardScaler().fit_transform(X)  # Feature scaling
    for train_size, test_size in splits:
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, train_size=train_size, test_size=test_size, random_state=42
        )
        for clf_name, (clf, param_grid) in classifiers.items():
            train_acc, test_acc, best_params, class_report = evaluate_classifier(
                clf, param_grid, X_train, y_train, X_test, y_test
            )
            detailed_results.append({
                "Dataset": dataset_name,
                "Classifier": clf_name,
                "Train Size": train_size,
                "Test Size": test_size,
                "Train Accuracy": train_acc,
                "Test Accuracy": test_acc,
                "Best Params": best_params,
                "Classification Report": class_report
            })

results_df = pd.DataFrame(detailed_results)

print(results_df)


# Bar plot of test accuracy
plt.figure(figsize=(12, 6))
sns.barplot(
    data=results_df,
    x="Dataset",
    y="Test Accuracy",
    hue="Classifier",
)
plt.title("Test Accuracy by Dataset and Classifier")
plt.ylabel("Test Accuracy")
plt.xlabel("Dataset")
plt.legend(title="Classifier")
plt.tight_layout()
plt.show()


# Extract Random Forest results for a specific dataset
rf_results = results_df[(results_df["Classifier"] == "Random Forest") & (results_df["Dataset"] == "Breast Cancer")]

# Heatmap of accuracy vs hyperparameters
pivot_table = rf_results.pivot(index="Train Size", columns="Test Size", values="Test Accuracy")
plt.figure(figsize=(8, 6))
sns.heatmap(pivot_table, annot=True, cmap="YlGnBu", fmt=".3f")
plt.title("Random Forest Accuracy Heatmap (Breast Cancer Dataset)")
plt.xlabel("Test Size")
plt.ylabel("Train Size")
plt.tight_layout()
plt.show()


# Function to generate a confusion matrix for a specific model
def plot_confusion_matrix(model, X_test, y_test, title="Confusion Matrix"):
    y_pred = model.predict(X_test)
    disp = ConfusionMatrixDisplay.from_predictions(y_test, y_pred, cmap="Blues")
    plt.title(title)
    plt.tight_layout()
    plt.show()

data = load_breast_cancer()
X, y = data.data, data.target
X = StandardScaler().fit_transform(X)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a Random Forest model
rf_model = RandomForestClassifier(max_depth=10, n_estimators=50, random_state=42)
rf_model.fit(X_train, y_train)

# Plot the confusion matrix
plot_confusion_matrix(rf_model, X_test, y_test, title="Confusion Matrix for Random Forest (Breast Cancer)")
